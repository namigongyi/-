<audio title="066_高级推荐模型之三：优化复杂目标函数" src="https://static001.geekbang.org/resource/audio/cb/0a/cbd82303c866d9cea8024adff69fae0a.mp3" controls="controls"></audio> 
<p><span class="orange"></span>周三我们讨论了协同矩阵分解，其主要思想就是解决多个两两关系的矩阵分解，并且希望能够建立隐变量之间的共享。</p>
<p>今天，我们来看一个稍微不一样的话题，那就是<strong><span class="orange">如何优化更加复杂的目标函数</span></strong>。</p>
<h2>为什么需要复杂的目标函数</h2>
<p>在介绍更复杂的目标函数之前，我们首先来回想一下，在之前的分享中，都接触到了哪些目标函数。</p>
<p>对于基于流行度或者相似度的推荐系统来说，其实并没有真正的目标函数的概念。这些推荐模型都是某种直观的“翻译”，这也导致了这些推荐系统很难直接使用在真实的应用中，往往是被当作特性用在其他模型中。</p>
<p>基于信息的推荐系统，本质上就是监督学习在推荐系统中的应用。因为是监督学习，那自然就需要目标函数。这里，经常是对点击率或者购买率进行建模，也就是说，经常使用<strong>二分分类的目标函数</strong>。</p>
<p>当我们使用矩阵分解的架构来对用户和物品的关系进行建模时，绝大多数情况下我们是在讨论<strong>评分</strong>。对于评分信息，常用的其实是<strong>线性回归</strong>（Linear Regression），也有学者使用<strong>泊松回归</strong>，因为泊松回归对于整数变量的建模要好于线性回归。当然了，矩阵分解也可以扩展到对点击率或者购买率的建模。</p>
<p>当年Netflix竞赛之后，Netflix公司把获奖的矩阵分解拿来进行实现，放入线上系统中，结果发现并没有本质性地提高推荐效果，这其实就和目标函数有关。虽然Netflix竞赛造就了矩阵分解等类似模型的流行，但是逐渐地，研究人员和工业界从业人员也意识到，<strong>用户对物品的评分，并不是推荐系统需要优化的目标，也就是说目标函数“选错了”</strong>。</p>
<p>那么，我们需要什么样的目标函数呢？</p>
<!-- [[[read_end]]] -->
<h2>高级目标函数</h2>
<p>直接对评分进行建模的最大问题，就是这和真实的推荐场景并不相符。不管是电商平台，还是新闻系统，我们并不是只在意用户对于某一些物品的评分。</p>
<p>真实的应用场景往往是这样的，用户打开应用，然后浏览一系列物品，由上往下进行翻阅，然后从中找到喜欢的物品。</p>
<p>这是不是很像我们在讨论搜索的时候，用户对于搜索结果的浏览？回忆一下，在搜索的场景中，我们首先输入关键字，然后搜索算法会返回一系列的结果。大多数情况下，我们会对返回的结果逐一检查。</p>
<p>在推荐场景下，我们虽然没有搜索关键词，但是整个从上往下的场景是类似的。</p>
<p>于是，我们就可以从搜索排序中得到启发，尝试对推荐结果进行排序。换句话说，我们并不在意用户的真实评分，或者我们是否能对用户和物品的喜好度进行完美估计，我们在意的是，<strong>能否把用户可能喜欢的物品排到前面去</strong>。</p>
<p><strong><span class="orange">把搜索系统中的排序思想利用到推荐系统中，是推荐系统的一个重大进步，这也让推荐系统和真实场景逐渐挂钩。</span></strong></p>
<p>那么，很直观的，要想更改推荐系统的行为，从评分的预测到排序学习，我们需要更改目标函数。</p>
<p>参考文献[1]中提出了一种叫<strong>BPR</strong>的方法，是把<strong>配对法</strong>引入到推荐系统中的一个重要工作。我们快速回忆一下已经在搜索系统中介绍过的“配对排序学习”。简单说来，配对法就是希望，对于某一个查询关键词来说，学习到每一对文档之间的关系，然后通过把所有的两两关系都预测正确，从而建立一个完整的排序结果。</p>
<p>很明显，在推荐系统的场景下，没有查询关键词，但是我们依然可以通过构造“<strong>会话</strong>”（Session）来学习排序。</p>
<p>简单来说，我们针对用户来到应用后产生的会话，对用户交互过的物品进行建模训练。我们期望能把有“正交互信息”的物品排到“负交互信息”的物品之前。</p>
<p>值得注意的是，和搜索不一样，推荐系统往往没有明确的反馈信息。意思就是，在搜索系统中，我们有已知的标签信息，也就是哪一个文档是“相关”的，哪一个是“不相关”的。然而，在推荐系统中我们并没有这样的信息。</p>
<p>因此，所有用户和物品的交互都是“<strong>隐回馈</strong>”（Implicit Feedback）。我们必须<strong>依靠假设来找到相关的物品</strong>。在这里，我们假定有正交互信息的物品是比其他物品更加相关。于是，正交互的物品的预测值要高。这里的“正交互”可以是点击、购买或者其他信息。这就是BPR的基本思路。</p>
<p>需要强调的一点是，BPR仅仅是一种思路框架，我们可以应用到矩阵分解中，以及基于信息的推荐系统等不同的模型中。我们可以把矩阵分解中的对于评分的目标函数换成基于BPR的目标函数，也就是进行配对法训练，得到的推荐系统能够更好地对物品进行排序。</p>
<p>有了这个思路，我们就可以打开一系列的想法了。比如，我们在前面的搜索模块中讲过，其实还可以直接优化类似NDCG、MAP这样的指标。那能不能把这些想法也搬运到推荐系统中去呢？</p>
<p>简单的回答是，能。但是这个流程也不是那么显然易见的，毕竟我们没有直接的标签信息，而且一般来说，这些目标函数本身就已经很难优化了，我们还要嫁接到矩阵分解或者是分解机等模型上，这就会让优化的难度继续攀升。今天我们就不展开讨论这部分内容了。</p>
<h2>小结</h2>
<p>今天我为你讲了推荐系统的另外一个问题，那就是目标函数。</p>
<p>一起来回顾下要点：第一，我们分析了为什么要关注目标函数，以评分为基础的目标函数的问题；第二，我们详细介绍了BPR这种非常经典的配对法的目标函数。</p>
<p>最后，给你留一个思考题，如果我们能够对所有物品的喜好度进行精准预测，是不是就不需要BPR了呢？学习排序和对物品喜好度的预测是完全不同的两件事，还是相互之间有联系呢？</p>
<p>欢迎你给我留言，和我一起讨论。</p>
<p><strong><span class="reference">参考文献</span></strong></p>
<p><span class="reference">1.  Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. BPR: Bayesian personalized ranking from implicit feedback. Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI '09). AUAI Press, Arlington, Virginia, United States, 452-461, 2009.</span></p>
<p></p>

<style>
    ul {
      list-style: none;
      display: block;
      list-style-type: disc;
      margin-block-start: 1em;
      margin-block-end: 1em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      padding-inline-start: 40px;
    }
    li {
      display: list-item;
      text-align: -webkit-match-parent;
    }
    ._2sjJGcOH_0 {
      list-style-position: inside;
      width: 100%;
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      margin-top: 26px;
      border-bottom: 1px solid rgba(233,233,233,0.6);
    }
    ._2sjJGcOH_0 ._3FLYR4bF_0 {
      width: 34px;
      height: 34px;
      -ms-flex-negative: 0;
      flex-shrink: 0;
      border-radius: 50%;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 {
      margin-left: 0.5rem;
      -webkit-box-flex: 1;
      -ms-flex-positive: 1;
      flex-grow: 1;
      padding-bottom: 20px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2zFoi7sd_0 {
      font-size: 16px;
      color: #3d464d;
      font-weight: 500;
      -webkit-font-smoothing: antialiased;
      line-height: 34px;
    }
    ._2sjJGcOH_0 ._36ChpWj4_0 ._2_QraFYR_0 {
      margin-top: 12px;
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-all;
      line-height: 24px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 {
      margin-top: 18px;
      border-radius: 4px;
      background-color: #f6f7fb;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._10o3OAxT_0 ._3KxQPN3V_0 {
      color: #505050;
      -webkit-font-smoothing: antialiased;
      font-size: 14px;
      font-weight: 400;
      white-space: normal;
      word-break: break-word;
      padding: 20px 20px 20px 24px;
    }
    ._2sjJGcOH_0 ._3klNVc4Z_0 {
      display: -webkit-box;
      display: -ms-flexbox;
      display: flex;
      -webkit-box-orient: horizontal;
      -webkit-box-direction: normal;
      -ms-flex-direction: row;
      flex-direction: row;
      -webkit-box-pack: justify;
      -ms-flex-pack: justify;
      justify-content: space-between;
      -webkit-box-align: center;
      -ms-flex-align: center;
      align-items: center;
      margin-top: 15px;
    }
    ._2sjJGcOH_0 ._3Hkula0k_0 {
      color: #b2b2b2;
      font-size: 14px;
    }
</style><ul><li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/10/22/69/c85fdb98.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>微微一笑</span>
  </div>
  <div class="_2_QraFYR_0">推荐系统一般分为召回模块和排序模块吧，前面说的矩阵分解属于召回 学习排序属于排序模块</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2018-03-16 10:08:36</div>
  </div>
</div>
</div>
</li>
<li>
<div class="_2sjJGcOH_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg"
  class="_3FLYR4bF_0">
<div class="_36ChpWj4_0">
  <div class="_2zFoi7sd_0"><span>林彦</span>
  </div>
  <div class="_2_QraFYR_0">如果我们真地有所有用户对所有物品的喜好度的精准预测，特别是除了用户喜欢的程度，也能把用户真正不喜欢的和用户未注意到的情况区别开来，并且不考虑这么多数据量的训练性能影响，则这个point-wise模型可以用来根据评分大小作排序，可以不需要 BPR。不过实际环境中这种理想状态很难达到。<br><br>现实中我们喜欢的，商业系统推荐的是一批物品，不是单个物品。展示位置，展示时间等因素会影响用户的感受，互动和之后的评价结果。把整个系统的预测效果看成一个整体，就需要融入排序效果的学习。排序学习这个过程则依赖于物品喜好度的预测，包括一对物品之间用户更喜好那个来优化目标函数。</div>
  <div class="_10o3OAxT_0">
    
  </div>
  <div class="_3klNVc4Z_0">
    <div class="_3Hkula0k_0">2018-03-16 12:55:09</div>
  </div>
</div>
</div>
</li>
</ul>